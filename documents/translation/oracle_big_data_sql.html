<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>[막번역] Apache Kafka 0.9.0 Documentation &middot; Taewan Kim</title>

  
  <link rel="stylesheet" href="http://taewan.kim/css/poole.css">
  <link rel="stylesheet" href="http://taewan.kim/css/hyde.css">
  <link rel="stylesheet" href="http://taewan.kim/css/poole-overrides.css">
  <link rel="stylesheet" href="http://taewan.kim/css/hyde-overrides.css">
  <link rel="stylesheet" href="http://taewan.kim/css/hyde-x.css">
  <link rel="stylesheet" href="http://taewan.kim/css/highlight/github2.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://taewan.kim/touch-icon-144-precomposed.png">
  <link href="http://taewan.kim/favicon.png" rel="icon">

<style>
ul#menu {
    list-style-type: none;
    margin: 0;
    padding: 0;
    overflow: hidden;
    background-color: #333;
}

ul#menu li {
    float: left;
}

ul#menu li a {
    display: block;
    color: white;
    text-align: center;
    padding: 14px 16px;
    text-decoration: none;
}

ul#menu li a:hover {
    background-color: #111;
}
</style>


  
  
  
  

  <meta name="description" content="">
  <meta name="keywords" content="kafka">
  
</head>
<body class="theme-base-08 layout-reverse">


<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      
        <img src="https://www.gravatar.com/avatar/e0994f88e71e61c3dede3a00e0e3dc00?s=200"
             alt="gravatar" title="Taewan Kim">
      
      <h1>Taewan Kim</h1>
      <p class="lead">민수아빠..</p>
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item"><a href="http://taewan.kim/">Blog</a></li>
      
      <li class="sidebar-nav-item"><a href="http://taewan.kim/post.html">all</a></li>
      
      <li class="sidebar-nav-item"><a href="http://taewan.kim/categories/bigdata.html">BigData</a></li>
      
      <li class="sidebar-nav-item"><a href="http://taewan.kim/categories/cloud.html">Cloud</a></li>
      
      <li class="sidebar-nav-item"><a href="http://taewan.kim/categories/linux.html">Linux</a></li>
      
      <li class="sidebar-nav-item"><a href="http://taewan.kim/categories/oracle.html">Oracle</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <a href="https://github.com/taewanme"><i class="fa fa-github-square fa-3x"></i></a>
      
      
      
      
      <a href="http://www.facebook.com/alvinkim082"><i class="fa fa-facebook-square fa-3x"></i></a>
      <a href="https://twitter.com/taewamme"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="http://taewan.kim/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>

    

    <p>Copyright &copy; 2016 <a href="http://taewan.kim/license/">License</a><br/>
       Powered by <a href="http://gohugo.io">Hugo</a></p>
  </div>
</div>

<ul id="menu">
  <li><a href="/">Home</a></li>
  <li><a href="/about.html">About Me</a></li>
  <li><a href="/presentation.html">Presentation</a></li>
  <li><a href="/document.html">Document</a></li>
  <li><a href="/mylearning.html">My Learning</a></li>
  <li><a href="/opc.html">Oracle Public Cloud</a></li>
  <li><a href="/minsu.html">My Son - Minsu</a></li>
</ul>


<div class="content container">
  <div>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-8469722754608892"
     data-ad-slot="5594090168"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  </div>
  <br/><br/>
  <div class="post">
    <h1>[막번역] Apache Kafka 0.9.0 Documentation</h1>
    

<blockquote>
<ul>
<li>출처: <a href="http://kafka.apache.org/documentation.html#introduction">http://kafka.apache.org/documentation.html#introduction</a></li>
<li>버전: 0.90</li>
<li>최종 업데이티:2016.04.06</li>
<li>친척률: 5%</li>
</ul>
</blockquote>

<h1 id="1-시작:02db276f177c9ea394e0f74e7b2c213a">1. 시작</h1>

<h2 id="1-1-소개:02db276f177c9ea394e0f74e7b2c213a">1.1 소개</h2>

<p>Kafka는 커밋 로그 서비스로 분산, 파티션, 복제의 특징을 갖는다. Kafka는 메세징 시스템 기능을 제공하며, 아주 특이한 디자인을 포함합니다.</p>

<p>이것이 무슨 의미일까요?</p>

<p>우선 몇 가지 기본 메세징 용어를 살펴보겠습니다.</p>

<ul>
<li>Topic: Kafka는 토픽이라고 불리는 메세지 저장소를 유지한다.</li>
<li>Producer: Kafka 토픽에 메세지를 발행(저장)하는 프로세스</li>
<li>Consumer: 토픽을 구독하고 발행된 메세지를 소비하는 프로세스</li>
<li>Broker: Kafka는 하나 혹은 다수의 서버로 구성된 클러스터로 동작함. 클러스터를 구성하는 서버를 Broker라고 함</li>
</ul>

<p>Producer는 네트웍을 통해서 Kafka 클러스터에 메세지를 전달한다. Kafka 클러스터는 다시 메세지를 Consumer에 다음과 같이 전달됩니다.</p>

<p><img src="http://kafka.apache.org/images/producer_consumer.png" alt="" /></p>

<p>클라이언트와 서버사이의 통신은 단순한 고성능 TCP 프로토콜을 이용합니다. 이 TCP 프로토콜은 언어 중립적입니다. Apache Kafka는 Kafka 자바 클라이어트를 제공합니다. 그러나 다수의 언어에서 이용 가능한 클라이언트를 이용 가능합니다.  <a href="https://cwiki.apache.org/confluence/display/KAFKA/Clients">https://cwiki.apache.org/confluence/display/KAFKA/Clients</a></p>

<h3 id="토픽과-로그:02db276f177c9ea394e0f74e7b2c213a">토픽과 로그</h3>

<p>토픽은 발행된 메세지의 카테고리명 혹은 피드명입니다. 각 토픽에 Kafka 클러스터는 분할된 로그를 다음과 같이 저장합니다.</p>

<p><img src="http://kafka.apache.org/images/log_anatomy.png" alt="" /></p>

<p>각 파티션은 순차적이며 불변의 메세지를 저장하는 연속체(시퀀스)로 지속적으로 커밋 로그가 추가됩니다. 이 파티션의 메세지에는 개별적으로 순차적으로 증가하는 id (숫자)가 할당됩니다. 이 id를 &ldquo;offset&rdquo;이라고 하며 파티션에서 각 메세지를 유일하게 식별합니다.</p>

<p>Kafka 클러스터는 모든 발행된 메세지를 설정된 기간동안 보관 합니다. 메세지의 소비 여부는 보관 결정에 관여하지 않습니다. 예를 들어서 log retaintion(로그 보관 주기 <sup class="footnote-ref" id="fnref:02db276f177c9ea394e0f74e7b2c213a:log-retaintion"><a rel="footnote" href="#fn:02db276f177c9ea394e0f74e7b2c213a:log-retaintion">1</a></sup>)이 2일로 설정되었다면 메세지가 발행된 후 이틀동안 해당 메세지는 소비될 수 있습니다. 그리고 이틀 후에는 저장 공간 확보를 위해서 폐기됩니다. Kafka 성능은 데이터 사이즈에 큰 영햐을 받지 않고 일정하게 유지됩니다. 따라서 많은 데이터를 보관하는 것이 문제가 되지는 않습니다.</p>

<p>consumer에서 관리되는 유일한 메타데이터는 로그에서의 Consumer의 위치 다시 말해 offset 입니다. 이 offset은 consumer가 관리합니다. 일반적으로 Consumer는 메세지를 읽을때 마다 자신의 offset을 선형적으로 증가시킵니다. 그러나 이 위치 정보는  Consumer가 관리 합니다. 그리고 원하는 순서대로 메세지를 읽어갈 수 있습니다. 예를 들어서 Consumer는 데이터 재처리를 위해서 오래된 offset으로 재설정할 수 있습니다.</p>

<p>이러한 특징들로 인하여 Kafka Consumer는 매우 저렴한 비용으로 관리 가능합니다. 또한 클러스터 혹은 다른 Consumer에 큰 영향을 미치지 않고 앞/뒤로 이동할 수 있습니다. 예를 들어서 기존 consumer가 어디까지 소비되었는지를 고려할 필요 없이, 모든 토픽의 내용을 &ldquo;tail&rdquo;하는 명령어를 사용할 수 있습니다. (역자주: 기존 Message Queue 방식에서는 불가능했던 오퍼레이션입니다. )</p>

<p>로그를 파티셔닝하는 것은 몇 가지 의도가 있습니다. 첫 번째, 파티셔닝을 통해서 로그를 확장 할 수 있습니다. 이러한 확장은 단일 서버의 규모를 넘어선 확장이 가능하게 합니다. 각 개별적인 파티션은 구동하는 호스트에 적합해야 합니다. 하나의 Topic은 여러개의 파티션을 갖을 수 있고 결고적으로 대규모 데이터를 처리할 수 있습니다. 두 번째는 파티션은 어느정도 병렬처리의 단위로써 작동합니다.</p>

<h3 id="distribution:02db276f177c9ea394e0f74e7b2c213a">Distribution</h3>

<p>로그 파티션은 kafka 클러스터의 여러 서버에 분산되어 있습니다. 클러스터의 각 서버는 데이터 처리하며 파티션의 공유를 요청합니다. 파티션은 설정된 수 만큼의 서버에 복제하여 장애 극복(Fault Tolerance)을 지원합니다.</p>

<p>각 파티션은 리더로써 동작하는 하나의 서버를 갖고 0개 혹은 그 아상 서버는 &ldquo;follower&rdquo;로 동작합니다. 리더는 파티션의 모든 읽기와 쓰기 요청을 처리합니다. 동시에 follower는 리더를 복제합니다. 리더에 장애가 발생하면 follower 중에 하나가 새로운 리더가 되며 이러한 처리는 자동화 되어 있습니다. 새로 선출된 그 리더는 해당 파티션에 대한 모든 읽기와 쓰기 요청을 처리합니다. 각 서버는 자신의 파티션의 일부에 대해서는 리더로 동작하고, 나머지 일부에 대해서는 follower로 동작합니다. 클러스터 내부에서 부하는 귱형을 맞추게 됩니다.</p>

<h3 id="producers:02db276f177c9ea394e0f74e7b2c213a">Producers</h3>

<p>Producer는 데이터를 자신이 선택한 토픽에 발행합니다. Producer는어떤 메세지를 토픽의 어떤 파티션에 저장할지를 결정하는 것을 전담합니다. 이러한 것은 부하를 분산하기 위해서 단순히 Round-robin 방식으로 동작되기도 하고 몇 가지 시멘틱 파티션 기능(메세지으 어떤 키를 기준으로 결정하는 바식)으로 동적합니다. 파티션을 사용에 관해서는 잠시후에 다루도록 하겠습니다.</p>

<h3 id="consumers:02db276f177c9ea394e0f74e7b2c213a">Consumers</h3>

<p>전통적인 메세징에서는 Queue와 Publish-subscribe 두 가지 모델있습니다. Queue 모델에서는 일련의 Consumer들로 풀(pool)을 구성하고 서버로 부터 메세지를 읽어습니다. 각 메세지는 consumer 풀중에 하나로 이동하게 됩니다. Publish-subscribe모델에서는 메세지는 모든 Consumer에 전달됩니다 (Broadcast). Kafka는 이 두가지 모델을 일반화한 하나의 consumer 모델인 &ldquo;consumer group&rdquo;을 제공합니다.</p>

<p>Consumer는 Consumer 그룹 명으로 스스로를 분류합니다. Topic에 발행된 각 메세지는 각 구독 consumer 그룹의 1개 consumer 인스턴스에 전달됩니다. Consumer 인스턴스는 독립된 프로세스이거나 별도의 서버에 위치 할 수 있습니다.</p>

<p>모든 consumer 인스턴스가 동일한 consumer 그룹을 갖는 상황이라면, 이러한 방식으로 작동하는 것은 전통적인 Queue 환경에서 여러 consumer에 부하를 분산하는 것과 유사하게 보입니다.</p>

<p>반대로 모든 consumer 인스턴스가 모두 다른 consumer 그룹을 갖는다면, 이러한 구성은 publish-subscribe 모델과 같이 동작합니다. 모든 메세지는 모든 consumer에 전달됩니다 (Broadcast)</p>

<p>일반적으로 Topic은 몇개의 consumer 그룹을 갖습니다. 각 그룹은 논리적인 구독자(subscriber)입니다. 각 그룹은 확장성과 장애 극복(Fault tolerance)을 위하여 복수의 consumer 인스턴스로 구성됩니다. 사실 이러한 구성은 구독자가 하나의 프로셋가 아닌 consumer 클러스터 형태인 publish-subscribe 시멘틱 구성과 같은 것 입니다.</p>

<hr />

<p><img src="http://kafka.apache.org/images/consumer-groups.png" alt="" /></p>

<p>그림 설명: 두 개의 kafka 클러스터는 4개의 파티셔닝(P0-P3)을 갖고 있으며, 2개의 consumer 그룹으로 구성되어 있습니다. Consumer 그룹 A는 두 개의 인스턴스를 갖고있고, Consumer 그룹 B는 4개의 consumer 인스턴스로 구성됩니다.</p>

<hr />

<p>Kafka는 전통적인 메세징 시스템보다 더 강력하게 순서를 보장합니다.</p>

<p>전통적인 Queue는 서버에 순서대로 메세지를 보관합니다. 복수의 consumer가 queue로 부터 메세지를 요청하면 서버는 메세지가 저장된 순서대로 consumer에 분해합니다. 그러나 서버가 순서대로 메세지를 Consumer에 분배하기는 했지만, 메세지는 consumer에 비동기적으로 전달됩니다. 따라서 메세지는 다른 consumer에 순서가 바뀌여 도착할 수 있습니다. 이는 사실상 메세지의 순서는 병렬처리에서는 무의미해 진다는 것을 의미합니다. 메세징 시스템은 종종 &ldquo;배타적 Consumer(exclusive consumer)&ldquo;의 개념으로 이러한 문제를 우회하기도 합니다. 배타적 consumer란 오직 queue로 부터 메세지를 소비하는 하나의 프로세스만을 허용하는 개념입니다. 그러나 이 방법은 병령 처리의 개념이 존재하지 않는 극단적인 편법입니다.</p>

<p>Kafka는 이 방법보다 개선된 방식을 제공합니다. 토픽내에 병렬 파티션 개념을 사용합니다. Kafka는 순서를 보장하면서 consumer 프로세스 풀에 부하를 분산시킬 수 있습니다. 이는 토픽의 파티션에 consumer 그룹의 consumer를 할당하여 완성됩니다. 이러한 구성을 통해서 consumer는 파티션의 유일한 리더되고 순서대로 데이터를 소비하게 됩니다. 많은 파티션이 존재하기 때문에 다수의 consumer 인스턴스로 부하술 분산하게 됩니다. 주의할 점은  consumer 그룹의  consumer 인스턴스의 갯수는 파티션 보다 많을 수 없습니다.</p>

<p>Kafka는 하나의 파티션내에서 메세지의 순서를 보장합니다. 토픽의 다른 파티션 사이에서는 순서를 보장하지 않습니다. 파티션 내에서 순서와 키를 기준으로한 파티션 데이터에 기능을 결합한다면 대부분 애플리케이션에 충족할 것 입니다. 그러나 메세지에 대한 전체 순서를 보장해야 하는 상황이라면 kafka를 하나 파티션만을 갖는 topic으로 구현할 수 있습니다. 물론 이 방식은 하나의 consumer 인스턴스만을 갖는 consumer 그룹을 사용해야 한다는 것을 의미합니다.</p>

<h3 id="kafaka가-보장하는-것:02db276f177c9ea394e0f74e7b2c213a">Kafaka가 보장하는 것</h3>

<p>Kafka는 다음과 같은 내용을 보자합니다.
- Producer가 특정 토픽 파티션에 전달한 메세지는 메세지가 전달된 순서대로 보일 것입니다. 즉 메세지 M1과 M2가 동일한 Proucer가 제출한 메세지이고 M1이 먼저 제출된 것이라면, M1에게는 M2보나 작은 offset이 할당되고 로그에서 앞에 위치하게 됩니다.
- consumer 인스턴스는 메세지가 로그에 저장된 순서대로 메세지가 보입니다.
- 복제 계수 N인 Topic에서 N-1개 서버 장애까지 로그에 저장된 메세지의 손실 없이 장애 극복 가능합니다.</p>

<p>Kafka가 보장하는 더 자세한 내용은 이 문서의 디자인 섹션에서 다루겠습니다.</p>

<h2 id="1-2-use-cases:02db276f177c9ea394e0f74e7b2c213a">1.2 Use Cases</h2>

<p>이 절에서는 아파치 Kafka의 유명한 사용 사례를 설명합니다. 추가적인 설명은 다음 블러그를 참조하시기 바랍니다. <a href="http://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying">Linkedin  Technical Blog</a></p>

<h3 id="messaging:02db276f177c9ea394e0f74e7b2c213a">Messaging</h3>

<p>Kafka는 다수의 전통적인 메세지 브로커를 대체하고 있습니다. Message Broker가 사용되는 이유는 다양합니다 (데이터 Producer로 부터 프로세스을 이원화고 처리되지 않은 메시지를 버퍼합니다.) 대부분의 메세지 시스템과 비교해 볼 때, Kafka는 더 좋은 처리량을 제공합니다. 또한 내장 파티션, 복제 그리고 장애 극복을 더 잘 제공합니다. Kafka는 대규모 확장 메세지 처리 애플리케이션에 적합한 솔루션입니다.</p>

<p>경험적으로 메세징 사용은 종종 상태적으로 낮은 처리량을 보인다. 그러나 낮은 대기 지연을 요구할 수 도 있다. 그리고 종종 Kafka가 제공하는 강력한 영속성 ㅂ장에 의존하기도 한다.</p>

<p>이 도메인에서 Kafka는 전통적인 메세징 시스템 (ActiveMQ와 RobbitMQ)와 비교할 수 있습니다.</p>

<h3 id="website-activity-tracking:02db276f177c9ea394e0f74e7b2c213a">Website Activity Tracking</h3>

<p>Kafka는 본래 실시간 publish-subscrive으로써 사용자 액티비티를 투적하는 파이프라인을 재구축할 수 있도록 하는 것 입니다. 이것은 사용자 액티비티(페이지뷰, 검색 혹은 다른 사용자가 취하는 움직임)를 액티비티 유형 별로 할당된 Topic를 갖는 중앙  Topic에 메세지를 발해하는 것을 의미합니다. 이러한 메세지 전달 방식은 실시간 프로세싱, 실시간 모니터링 그리고 하둡과 오프라인 데이터 웹어하우스 시스템으로 데이터 로딩하여 오프라인 프로세싱과 리포팅을 포함하는 다양한 범위에 응용할 수 있습니다.</p>

<p>사용자 페이지 뷰를 위한 다수의 액티비티 메세지를 생성하기 때문에 액티비티 트래킹은 종종 매우 높은 규모를 보입니다.</p>

<h3 id="metrics:02db276f177c9ea394e0f74e7b2c213a">Metrics</h3>

<p>Kafka는 종종 운영 모니티러이 데이터로 사용됩니다. 분산된 애플리케이션으로 부터 집계 통계를 구현하여 운영 데이터에 중앙 집중하된 데이터 전달을 만들 수 있습니다.</p>

<h3 id="log-aggregation:02db276f177c9ea394e0f74e7b2c213a">Log Aggregation</h3>

<p>대다수의 사람들은 Kafka를 로그 수집 솔루션를 위한 대안으로 Kafka를 사용합니다. 로그 수집은 전통적으로 외부 서버에 위치한 물리적 로그 파일을 수집하고 로그를 처리하기 위채서 중앙 저장소에 저장합니다. 중앙 저장소로는 파일서버나 HDFS가 이용됩니다. Kafka는 파일의 세부 정보로 부터 분리되고 로그 혹은 메세지 스트림 같은 이벤트 데이터에 대한 더 명확한 추상화를 제공합니다. 따라서 더 낮은 지연 처리와 복수 데이터 소스와 분산 데이터 소비에 대한 더 쉬운 지원을 가능하게 합니다. Scrive 혹은 Flume과 같은 로그 중심 시스템과 비교해 볼 때, Kafka는 상당히 좋은 성능, 복제에 기인한 더 강력한 데이터 연속성 보장, 더 낮은 지연 처리 시간을 제공합니다.</p>

<h3 id="stream-processing:02db276f177c9ea394e0f74e7b2c213a">Stream Processing</h3>

<p>많은 사용자는 Topic의 미처리 데이터(raw data)로 부터 소비한 데이터를 단계적인 프로세스로 처리하게 됩니다. 미 처리 데이터를 읽어서 합계를 내고, 데이터를 보강하고 혹은 추가적인 전달을 위해서 변환하여 새로운 Kafka topic에 전달합니다. 예를 들어서 기사 추천(article recommendation)용 프로세스 흐름은 RSS로 부터 기사 내용을 크롤링(Crawl)하고 그 데이터를 article topic에 전달합니다. 추가적인 프로세스는 데이터를 정규화하거나 깨끗한 기사 내용을 위하셔 컨텐츠를 정재하는 작업을 수행합니다. 마지막 단계에서 사용자에게 이 컨텐츠를 매칭합니다. 이러한 방식은 개별적인 topic으로 부터 실시간 데이터 프름의 그래프를 생성합니다.  이러한 종류의 변환을 구현하는 가장 유명한 프레임웍은  <a href="https://storm.apache.org">Storm</a>과 <a href="http://samza.apache.org">Samza</a> 입니다.</p>

<h3 id="event-sourcing:02db276f177c9ea394e0f74e7b2c213a">Event Sourcing</h3>

<p><a href="http://martinfowler.com/eaaDev/EventSourcing.html">Event Sourcing</a>은 상태 변경이 시간 순서대로 레코드로 기록되는 애플리케이션 디자인 스타일입니다. 이러한 대규모 로그 데이터 저장 기능을 제공하는 kafka는 Enent Sourcing 스타일의 애플리케이션의 훌령한 백엔드 입니다.</p>

<h3 id="commit-log:02db276f177c9ea394e0f74e7b2c213a">Commit Log</h3>

<p>Kafka는 분산 시스템을 위한 외부 커밋-로그의 한가지 형태로 동작합니다. 로그는 노드들 사이에 데이터 복제되고 장애난 노드의 재동기화 매카니즘으로 동작하며 결과적으로 데이터를 복구합니다. Kafka에서 로그 데이터 압축 기능은 이러한 것들을 돕습니다. Commit Log 방식에서는 Kafka가 Apache BookKeeper와 유사하게 이용됩니다. .</p>

<h2 id="1-3-quick-start:02db276f177c9ea394e0f74e7b2c213a">1.3 Quick Start</h2>

<p>본 튜토리얼은 kafka를 처음 시작하고 기존에  kafka와 Zookeeper 데이터가 존재하지 않나고 가정합니다.</p>

<h3 id="step-1-코드-다운로드:02db276f177c9ea394e0f74e7b2c213a">Step 1: 코드 다운로드</h3>

<p>Apache Kafka 0.9.0.0 버전 [다운로드] 및 압축 풀기</p>

<pre><code class="language-bash">taewan@kafka $tar -xvf kafka_2.11-0.9.0.0.tgz 
x kafka_2.11-0.9.0.0/
x kafka_2.11-0.9.0.0/LICENSE
//로그생략
x kafka_2.11-0.9.0.0/libs/lz4-1.2.0.jar
taewan@kafka $cd kafka_2.11-0.9.0.0
</code></pre>

<h3 id="step-2-서버-시작:02db276f177c9ea394e0f74e7b2c213a">step 2: 서버 시작</h3>

<p>Kafka는 Zookeeper를 사용합니다. 따라서 가장 먼저 Zookeeper 서버를 시작해야 합니다. 이 글을 읽는 독자중 현재 사용하고 있는 Zookeeper가 없는 상황이라면, Kafka 패키지에 포함된 스크립트를 사용하여 단일 노드로 구성된 Zookeeper 인스턴스를 바로 시작할 수 있습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/zookeeper-server-start.sh config/zookeeper.properties 

[2016-04-08 17:19:31,254] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
//로그 생량
</code></pre>

<p>이제는 kafka 서버를 시작합니다. (역자주: 별도의 터니멀을 오픈하여 kafka 서버를 시작합니다. )</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $pwd
/Users/taewan/temp/kafka/kafka_2.11-0.9.0.0
taewan@kafka_2.11-0.9.0.0 $bin/kafka-server-start.sh config/server.properties 
[2016-04-08 17:21:54,625] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
//로그 생략
</code></pre>

<h3 id="topic-생성하기:02db276f177c9ea394e0f74e7b2c213a">Topic 생성하기</h3>

<p>Topic 명이 &ldquo;test&rdquo;이고 단일 파티션과 단일 복제를 갖는 Topic을 생성합니다.</p>

<blockquote>
<p>bin/kafka-topics.sh &ndash;create &ndash;zookeeper localhost:2181 &ndash;replication-factor 1 &ndash;partitions 1 &ndash;topic test</p>
</blockquote>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
Created topic &quot;test&quot;.
taewan@kafka_2.11-0.9.0.0 $
</code></pre>

<p>list 명령을 사용하여 topic의 목록을 확인 할 수 있습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-topics.sh --list --zookeeper localhost:2181
test
taewan@kafka_2.11-0.9.0.0 $
</code></pre>

<p>수작업으로 topic을 생성하지 않고 메세지를 발행하는 topic이 존재하지 않을때 topic이 자동으로 생성되도록 broker를 구성할 수 있습니다.</p>

<h3 id="step-4-메세지-전달하기:02db276f177c9ea394e0f74e7b2c213a">Step 4: 메세지 전달하기</h3>

<p>Kafka는 파일 혹은 표준 입력으로 부터 입력을 받아 메세지를 kafka 클러스터에 전달하는 커맨드 라인 클라이언트를 제공합니다. 각 라인이 개별적인 메세지로 전송됩니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
첫번째 메세지
두번째 메세지
</code></pre>

<h3 id="step-5-consumer-실행하기:02db276f177c9ea394e0f74e7b2c213a">step 5: Consumer 실행하기</h3>

<p>Kafka는 또한 커맨드 라인 툴로 consumer를 제공합니다. 이 툴은 표준 출력으로 메세지를 출력합니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
첫번째 메세지
두번째 메세지
</code></pre>

<p>각기 다른 터미널에 위 명령을 각각 실행하고, produder 터미널에서 메세지를 입력하면, consumer 터미널에서 앞에서 입력한 메세지와 동일한 메세지가 출력될 것 입니다.</p>

<p>모든 컴맨드 라인 툴들은 추가적인 옵션을 갖습니다. 파라미터 없이 커맨드를 입력하면 이들 명령에 대한 자세한 사용법과 추가적인 정보가 출력 됩니다.</p>

<h3 id="복수-브로커-클러스터-설정하기:02db276f177c9ea394e0f74e7b2c213a">복수 브로커 클러스터 설정하기</h3>

<p>지금까지 우리는 하나의 브로커를 구동하는 것을 확인하였습니다 그러나 이러한 예제는 현실적이지 않습니다. Kafka  에서 단일 브러커는 사이즈가 1인 클러스터 입니다. 복수의 브로커를 구성할 때 많은 변경이 발생하는 것은 아닙니다. 이번에는 하나의 서버에 3개의 노드로 클러스터를 확장해 보겠습니다</p>

<p>우선 브로커 별로 설정 파일을 생성합니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $cp config/server.properties config/server-1.properties
taewan@kafka_2.11-0.9.0.0 $cp config/server.properties config/server-2.properties
taewan@kafka_2.11-0.9.0.0 $ls -al config/server*.properties
-rw-r--r--@ 1 taewan  staff  5589  4  8 19:44 config/server-1.properties
-rw-r--r--@ 1 taewan  staff  5589  4  8 19:44 config/server-2.properties
-rw-r--r--@ 1 taewan  staff  5589 11 21 09:53 config/server.properties
taewan@kafka_2.11-0.9.0.0 $

</code></pre>

<p>새로 만든 두 프로퍼티 파일을 편집하여 다음과 같이 수정합니다.</p>

<pre><code>config/server-1.properties:
    broker.id=1
    port=9093
    log.dir=/tmp/kafka-logs-1

config/server-2.properties:
    broker.id=2
    port=9094
    log.dir=/tmp/kafka-logs-2
</code></pre>

<p>broker.id 프로퍼티는 클러스터의 각 노드의 유일하고 영구적인 이름을 설정합니다. 또한 포트 번호와 로그 디렉토리를 수정해야 합니다. 이 두 프로퍼티를 수정하는 이유는 현재 예제는 모두 하나의  머신에서 동작하기 때문이고 그리고 이 예제에서는 브로커가 동일한 포트를 등록하거나 서로이 데이터를 덮어쓰는 것으로 부터 브로커를 보호하길 원하기 때문입니다</p>

<p>우리는 이미 ZooKeeper를 갖고 있고 하나의 노드를 시작한 상태입니다. 따라서 두 개의 새로운 노드를 시작해야 합니다.</p>

<pre><code>&gt; bin/kafka-server-start.sh config/server-1.properties &amp;
&gt; bin/kafka-server-start.sh config/server-2.properties &amp;
</code></pre>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-server-start.sh config/server-1.properties &amp;
taewan@kafka_2.11-0.9.0.0 $bin/kafka-server-start.sh config/server-2.properties &amp;
</code></pre>

<p>복제 계수가 3인 새로운 토픽을 생성:</p>

<pre><code class="language-bash">&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
</code></pre>

<p>이제 어떤 브로커가 어떻게 동작하는지를 클러스터로 부터 확인 하는 방법을 알아볼 차례입니다. 이러한 정보를 확인하기 위해서 descrive topic 명령을 사용합니다.</p>

<pre><code class="language-bash">bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
</code></pre>

<p>describe 명령의 출력을 살펴보겠습니다. 첫번째 라인은 모든 파티션의 요약 정보를 제공합니다. 그 아래 추가된 라인은  파티션 단위의 정보입니다. 우리는 오직 하나의 파티션만을 갖도록 토픽을 만들었기 때문에 위 툴력 결과는 오직 하나의 라인만을 갖습니다.</p>

<ul>
<li>leader: 해당 파티션의 읽기와 쓸기를 책임지는 파티션 입니다. 모든 노드 중 랜덤으로 선택된 1개 노드는 leader가 될 것입니다.</li>
<li>replicas: 해당 파티션 로그를 복제하는 노두의 목록으로, 나열된 목록은 leader의 여부, 현재 활성화 여부와 관계 없습니다.</li>
<li>Isr: &ldquo;in-sync&rdquo; 복제의 집합입니다. 이는 replia 목록의 부분 집합으로 현재 활성화 되여 있고 리더로 리더인 목록입니다.</li>
</ul>

<p>예제에서 주의할 점은 node 1이 토픽의 유일한 파티션에 대한 리더라는 것입니다.</p>

<p>앞에서 생성한 최초의 토픽에 대하여 동일한 명령을 실행하여 다음과 같은 결과를 확인 할 수 있습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test
Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
taewan@kafka_2.11-0.9.0.0 $
</code></pre>

<p>test Topic이 복제목록이 없고 서버 0만이 존재하는 것은 당연한 것입니다.</p>

<p>이제 새로운 topic에 새로운 메세지를 전달해 보겠습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
첫번째 메세지
두번째 메세지

</code></pre>

<p>이제 메세지를 소비해 보겠습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
첫번째 메세지
두번째 메세지

</code></pre>

<p>이제 장애 극북을 테스트해 보겠습니다. 현재 Broker 1이 리더로 활성화 되어 있습니다. 그럼 리더 Brokder를 프로세스 종료해 보겠습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $ps | grep server-1.properties
19249 ttys005    1:07.13 /Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true -Xloggc:/Users/taewan/temp/kafka/kafka_2.11-0.9.0.0/bin/../logs/kafkaServer-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/Users/taewan/temp/kafka/kafka_2.11-0.9.0.0/bin/../logs -Dlog4j.configuration=file:bin/../config/log4j.properties -cp :/Users/taewan/temp/kafka/kafka_2.11-0.9.0.0/bin/../libs/* kafka.Kafka config/server-1.properties
35359 ttys008    0:00.00 grep server-1.properties
taewan@kafka_2.11-0.9.0.0 $kill -9 19249
taewan@kafka_2.11-0.9.0.0 $
</code></pre>

<p>leader는 슬레이브 중 하나로 변경되었습니다 그리고 node 1은 더 이상 &ldquo;in-sync replica set&rdquo;에 포함되지 않습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 0	Replicas: 0,2,1	Isr: 2,0
</code></pre>

<p>초기에 선출된 리더는 현재 다운상태이지만 메세지의 소비는 여전이 이용가능 합니다.</p>

<pre><code class="language-bash">aewan@kafka_2.11-0.9.0.0 $ bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
첫번째 메세지
두번째 메세지

</code></pre>

<p>Step 7: Kafka connect를 사용하여 데이터 임포트/익스포트 하기</p>

<p>콘솔에 데이터를 작성하고 다시 콘솔에 데이터를 출력하는 것은 처음 시작할때에나 적합한 방식입니다. 아마도 다른 데이터 소스로 부터 데이터를 사용하거나 Kafka로 부터 다른 시스템에 데이터를 보내는 것을 원할 것입니다. 다른 시스템을 위하여 사용자 정의 통합 코드를 적성하는 것 대신에, 데이터를 임포트하고 익스포트 하는 용도로 kafka 커넥터를 사용할 수 있습니다. Kafka 커넥터는 kafka에 데이터를 임포트하고 익스포트하는 툴로 kafka 배포 패지키에 포함되어 있습니다. Kafka 커넥터는 외부 시스템과 함께 상호작용하기 위한 사용자 정의 로직을 구현하는 커넥터를 구동하는 확장 툴이다. 현재 &ldquo;Quick Start&rdquo; 절에서, 파일로 부터 데이터를 임포트하고 파일에 Topic의 파일을 익스포트하는 단순한 커넥터를 살펴보겠습니다. 먼저, 테스트를 위한 기본 데이터를 만들어 보겠습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $echo -e &quot;foo\nbar&quot; &gt; test.txt
taewan@kafka_2.11-0.9.0.0 $cat test.txt 
foo
bar
taewan@kafka_2.11-0.9.0.0 $
</code></pre>

<p>다음으로, 단일 구동 모드로 두 개의 커넥터를 시작시킬 것입니다. 즉 이 두 커넥터는 단일, 로컬, 전용 프로세스라는 것을 의미합니다. Kafka 베포 패지키에는 이 데모를 위한 설정 파일 3개를 파마미터로써 제공합니다. 첫번째 설정 파일은 Kafka 커텍터 프로세스를 위한 설정입니다. 일반적으로 kafka 브러커의 접속 정보와 데이터에 대한 직렬화 포멧 정보 들이 포함됩니다.  나머지 설정 파일은 커넥터 생성을 담당합니다. 이 파일들에는 유일한 커넥터 명, 초기화 커넥터 클래스 그리고 커넥터에 필요한 기타 설정이 포함됩니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
[2016-04-10 23:39:39,843] INFO StandaloneConfig values: 
//생략
</code></pre>

<p>Kafka 배포 패키지에 포함되어 있는 샘플 설정 파일은 기본 로컬 클러스터 구성을 사용합니다. 그리고 두 개 커넥터를 생성합니다. 첫번째는 소스 커넥터이고 입력 파일로 부터 줄 단위로 읽어들입니다. 그리고 kafka topic에 전달합니다. 두 번째는 Sink 커넥터로 kafka topic으로 부터 kafka topic에서 메세지를 읽어서 출력 파일에 줄 단위로 출력합니다. 명령어를 시작하면 커넥터를 초기화하는 내용을 포함하는 몇 줄의 로그 세세지를 볼 것입니다. Kafka 커넥터 프로세스가 시작되면, 소스 커넥터는 test.txt로 부터 줄단위로 읽어 들이기 시작합니다. 그리고 topic 명이 connect-test에 메세지를 전달하면, sink 커넥터는 topic명이 connect-test에서 메세지를 읽어서 test.sink.txt에 저장합니다.</p>

<p>출력 파일의 내용을 확인하는 것으로 예제 커넥터로 전체 파이프라인을 통해서 모든 데이터가 전달되는지는 점증할 수 있습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $cat test.sink.txt 
foo
bar
taewan@kafka_2.11-0.9.0.0 $
</code></pre>

<p>데이터는 kafka Topic(connect-test)에 저장됩니다. 따라서 Topic에 저장되는 데이터를 살펴보는 목적으로 console consumer를 시작하거나 데이터 처리용도로 사용자 정의 코드를 시작할 수 있습니다.</p>

<pre><code class="language-bash">taewan@kafka_2.11-0.9.0.0 $bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic connect-test --from-beginning
{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;foo&quot;}
{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;bar&quot;}

</code></pre>

<p>커넥터는 지속적으로 데이터를 처리합니다. 따라서 입력 파일에 데이터를 추가하면 그 데이터는 파이프라인을 통해서 이동하게 됩니다.</p>

<pre><code>&gt; echo &quot;Another line&quot; &gt;&gt; test.txt
</code></pre>

<p>추가된 데이터는 consumer consumer와 sink 파일에서 확인 가능합니다.</p>

<h2 id="1-4-ecosystem:02db276f177c9ea394e0f74e7b2c213a">1.4 Ecosystem</h2>

<p>Kafka 배포 패키지외에도 Kafkadㅘ 통합된 수 많은 툴들이 있습니다. <a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">에코시스템 페이지</a>에tjsms 이들에 대한 목록을 제공합니다. 대표적인 사용 분야는 스트림 프로세스 시스템, 하둡 통합, 모니터링, 배포툴 등입니다.</p>

<h2 id="1-5-이전-버전으로-부터의-업그레이드:02db276f177c9ea394e0f74e7b2c213a">1.5 이전 버전으로 부터의 업그레이드</h2>

<h3 id="0-8-0-0-8-1-x-0-8-2-x에서-0-9-0-0로-업그데이드:02db276f177c9ea394e0f74e7b2c213a">0.8.0, 0.8.1.X,0.8.2.X에서 0.9.0.0로 업그데이드</h3>

<p>0.9.0.0은 잠재적으로 준단되는 변경사항(Potential Breaking Changes)이 있으므로 업그레이드 전에 확인이 필요합니다. 그리고 내부 브로커 프로토콜이 이전 버전으로 부터 변경되었습니다. 이것은 업그레이드된 브로커와 클라이언트가 이전 버전과 호환되지 않을 가능성 도 있습니다. 중요한 점은 바로 클라이언트를 업그레이드 하기 전에 kafka 클러스터를 업그레이드 해야 한다는 것입니다. 현재 MirrorMaker Downstream 클러스터를 사용하고 있다면, 우선 업글레이드 해야 합니다.</p>

<p><strong>Roling 업그레이드</strong>
- 모든 브로커의 server.properties파일을 업데이트하고 다음 프로퍼티를 추가
  - <code>inter.broker.protocol.version=0.8.2.X</code>
- 브로커 업그레이드 수행, 업그레이드는 브로커를 다운시킨 상태에서 코드 업그레이드 후 재시작으로 완료됨
- 전체 클러스터를 업그레이드할 때, <code>inter.broker.protocol.version</code>를 수정함으로써 프로토콜 버전 충돌 발생, 버전을 0.9.0.0으로 설정
- 새로운 프로토콜 버전을 적용하기 위해서 브로커를 하나씩 재시작</p>

<p><strong>주의사항</strong>: 다운타임이 허용된다면, 모든 브로커를 다운시키고 코드를 업뎅트하고 재시작하면됩니다. 재지삭된 클러스터는 기본적으로 새로운 프로토콜로 시작될 것입니다.</p>

<p><strong>주의사항</strong>: 프로토콜 버전 교체와 재시작은 브로커를 업그레이드한 후에 수행될 수 있습니다.  이러한 절차가 업그레이드 후 즉시 수행될 필요는 없습니다.</p>

<p><strong>잠재적 중지 변겨: 0.9.0.0</strong>
- Java 1.6 지원 중단
- Scala 2.9 지원 중단
- 1000 이상의 Broker ID는 자동 할당되는 Broker ID로 예약됨. 클러스터의 기존 Broker ID가 임계값 이상이라면 브로커 설정 프로퍼티인<code>reserved.broker.max.id</code> 속성을 증가하는 설정을 해야 합니다.
- 설정 파라미터 <code>replica.lag.max.messages</code>는 제거되었습니다. 파티션 리더는 더 이상 복제가 진행중인지를 결정할 때 지연 메세지의 수를 더이상 고려하지 않습니다.
- 설정 파라미터 <code>replica.lag.time.max.ms</code>는 복제로 부터 마지막 패치 요청이래로 경과 시간과 복제가 마지막 잡애낸 이후 경과 시간을 모두 포함합니다. 리더로 부터 메세지를 패치는 하지만 replica.lag.time.max.ms의 범위를 초과하여 최근 메세지를 잡지 못하는 복제는 동기화에 문제가 있는 것으로 평가합니다.
- 압축된 topic은 더이상 키가 없는 메세지를 허용하지 않습니다. 키가 없을 경우 proucer는 예외를 발생시킵니다. 0.8.x에서 키가 없는 메세지는 연속적인 이슈로 로그 압축의 위협을 발생시킵니다. 그리고 모든 압축 topic 압축이 중지됩니다.
- MirrorMaker는 더이상 복수 대상 클러스터를 지원하지 않습니다. 결고적으로 오직 하나의 단일 클러스터만을 수용합니다(consumer.config). 복수의 소스 클러스터를 미러링하기 위해서 최소한 소스 클러스터 별로 하나의 MirrorMaker 인스턴스가 필요합니다. 각각은 consumer 설정에 매칭됩니다.
- org.apache.kafka.clients.tools.* 패키지 아래의 툴은 org.apache.kafka.tools.*로 이동되었습니다. 관련 스크립트는 여전히 도일하게 동작합니다. 오로지 커스텀 코드에서 클래스 임포트 부분만 변경이 되었습니다.
- 기본  Kafka JVM 성능 옵션(KAFKA_JVM_PERFORMANCE<em>OPTS)은 kafka-run-class.sh에서 변경되었습니다.
- kafka-topics.sh 스크립트(kafka.admin.TopicCommand)은 장애에 대한 제로를 반환하지 않는  exit 코드입니다.
- kafka-topics.sh 스크립트(kafka.admin.TopicCommand)은 Topic명이 메크릭 충동과 위협할 때 경고를 출력합니다. 예를 들어서 &ldquo;.&rdquo; 혹은 &ldquo;</em>&ldquo;를 사용할 topic 명으로 사용할 때 입니다. 실제 충돌이 발생할 경우에는 에러를 출력합니다.<br />
- kafka-console-producer.sh 스크립트는 디폴트로 이전 버전 Producer가 아닌 새로운 버전의 producer를 사용할 것입니다. 이전 버전의 producer를 사용하기 위해서는 <code>old-producer</code>를 지정해야 합니다<br />
- 모든 커맨드 라인 툴은 모든 로그 메세지를 stdout이 아닌 stderrdㅔ 모든 모그 메세지를 출력합니다.</p>

<p>__ 0.9.0.0.1 주목할 변화__
- 새로운 idrㅏ 생성되는 기능는 비활성화 처리됨.<code>broker.id.generation.enable</code>의 기본 값은 false.
- <code>log.cleaner.enable</code> 설정 파라미터의 기본 값은 true입니다. <code>cleanup.policy=compact</code> 설정된 topic은 기본적으로 압축 됩니다. 기본 128MB의 힙이 cleaner 프로세스에 할당되어 있으며, 이 프로세스 사이즈는  <code>log.cleaner.dedupe.buffer.size</code>에서  설정 가능합니다. 사용자는 압축된  topic의 사용에 근거한 log.cleaner.depupe.buffer.size와 log.cleaner 설정 값을 재검토하기를 원할 수 있습니다.<br />
- 새로운 consumer에 대하여 fetch.min.bytes의 설정 파라미터의 기본 값은 현재 1입니다.</p>

<p>__ 0.9.0.0에서 Deprecations된 변경__
- kafka-topics.sh 스크립트(kafka.admin.TopicCommand)로 부터 topic 설정을 변경하는 것은 deplecate되었습니다. 앞으로 topic 설정 변경을 하는 용도로 kafka-configs.sh 스크립트(kafka.admin.ConfigCommand)를 사용하는 것이 권고됩니다.<br />
- kafka-consumer-offset-checker.sh(kafka.tools.ConsumerOffsetChecker)는 deplecate되었습니다. 앞으로 kafka-consumer-groups.sh(kafka.admin.ConsumerGroupCommand) 를 사용하는 것이 권장됩니다.
- kafka.tools.ProducerPerformance 클래스는 deplecate되었습니다. 앞으로 org.apache.kafka.tools.ProducerPerformance 사용할 것을 권고합니다. kafka-producer-perf-test.sh 역시 새로운 클래스로 변경될 것입니다.</p>

<h3 id="0-8-1에서-0-8-2로-업그레이드:02db276f177c9ea394e0f74e7b2c213a">0.8.1에서 0.8.2로 업그레이드</h3>

<p>0.8.2는 0.8.1과 하위 호환성을 지원합니다. 업그레이드는 한 브로커에서 수행되며, 비활성화,  코드 업그레이드, 재시작으로 완료됩니다.</p>

<h3 id="0-8-0에서-0-8-1로-업그레이드:02db276f177c9ea394e0f74e7b2c213a">0.8.0에서 0.8.1로 업그레이드</h3>

<p>0.8.1는 0.8.0과 하위 호환성을 지원합니다. 업그레이드는 한 브로커에서 수행되며, 비활성화, 코드 업그레이드, 재시작으로 완료됩니다.</p>

<h3 id="0-7로-부터-업그레이드:02db276f177c9ea394e0f74e7b2c213a">0.7로 부터  업그레이드</h3>

<p>릴리즈 0.7은 새로운 버전과 호환성을 제공하지 않습니다. 주요 변경은 복제 기능을 추가하기 위하여 API, ZooKeeper 데이터 스트럭처, 프로토콜 그리고 설정에 이루어 졌습니다. 0.7에서 이후 버전으로 업그레이드는 마이그레이션을 위햔 특별한 <a href="https://cwiki.apache.org/confluence/display/KAFKA/Migrating+from+0.7+to+0.8">툴</a>이 필요합니다. 이 마이그레이션은 다운타임 없이 수행될 수 있습니다.</p>

<h1 id="2-api:02db276f177c9ea394e0f74e7b2c213a">2. API</h1>

<p>아파치 카프카는 새로운 자바 클라이언트를 포함하여 기존 scala 클라이언트를 부충한다는 의미입니다. 위치는 org.apache.kafka.clients입니다. 그러나 호환성을 위하여 기존 클라이언트도 공존합니다. 이들 클라이언트는 최소한의 의존서으로 별도의 jar로 이용가능합니다. 기존의 스칼라 클라이언트는 서버와 같은 패키지에 위치합니다.</p>

<h2 id="2-1-producer-api:02db276f177c9ea394e0f74e7b2c213a">2.1 Producer API</h2>

<p>새로운 자바 프로듀서를 사용하기 위해서 모든 새로운 개발이 요구되었습니다. 이 클라이언트는 검증된 제품으로 기본 스칼라 클라이언트 보다 더 빠르고 더 완전한 기능을 탑재하고 있습니다. 사용자는 다음과 같은 메이븐 관리 기능을 사용하여 클라이언트 jar의 의존성을 추가하여 사용할 수 있습니다. (새로운 버전이 릴리즈 되면 버전 넘버를 변경해야 합니다.)</p>

<pre><code class="language-xml">&lt;dependency&gt;
	    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
	    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
	    &lt;version&gt;0.9.0.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<p>producer 를 사용하는 방법을 소개하는 예제는 다음 javadoc에서 확인 가능합니다. =&gt; <a href="http://kafka.apache.org/090/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html">예제코드</a></p>

<p>이전 버전의 scala producer api에 대하여 정보가 필요하다면 다음 링크를 이용하여 정보를 찾을 수 있습니다. : <a href="http://kafka.apache.org/081/documentation.html#producerapi">이전 버전</a></p>

<h2 id="2-2-consumer-api:02db276f177c9ea394e0f74e7b2c213a">2.2 Consumer API</h2>

<p>0.9.0릴리즈 부터, 기존의 고수준 Zookeeper 기반 consumer와 저수준 Consumer API를 대체하기 위하여 새로운 자바 Consumer를 추가하였습니다. 이 클라이언트는 베타 품질이 적용되어 있습니다. 사용자의 원할한 업그레이드를 보장하기 위히서, 0.9 kafka 클러스터에서도 0.8 consumer 클라이언트를 유지할 수 있습니다. 다음 절에서 0.8 consumer (고수준 consumerConnector와 저수준 Simple Consumer)와 새로운 자바 consumer API를 각각 소개할 것입니다.</p>

<h3 id="2-2-1-이전-버전-고-수준-consumer-api:02db276f177c9ea394e0f74e7b2c213a">2.2.1 이전 버전 고 수준 Consumer API</h3>

<pre><code class="language-java">
class Consumer {
  /**
   *  Create a ConsumerConnector
   *
   *  @param config  at the minimum, need to specify the groupid of the consumer and the zookeeper
   *                 connection string zookeeper.connect.
   */
  public static kafka.javaapi.consumer.ConsumerConnector createJavaConsumerConnector(ConsumerConfig config);
}

/**
 *  V: type of the message
 *  K: type of the optional key assciated with the message
 */
public interface kafka.javaapi.consumer.ConsumerConnector {
  /**
   *  Create a list of message streams of type T for each topic.
   *
   *  @param topicCountMap  a map of (topic, #streams) pair
   *  @param decoder a decoder that converts from Message to T
   *  @return a map of (topic, list of  KafkaStream) pairs.
   *          The number of items in the list is #streams. Each stream supports
   *          an iterator over message/metadata pairs.
   */
  public &lt;K,V&gt; Map&lt;String, List&lt;KafkaStream&lt;K,V&gt;&gt;&gt;
    createMessageStreams(Map&lt;String, Integer&gt; topicCountMap, Decoder&lt;K&gt; keyDecoder, Decoder&lt;V&gt; valueDecoder);

  /**
   *  Create a list of message streams of type T for each topic, using the default decoder.
   */
  public Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; createMessageStreams(Map&lt;String, Integer&gt; topicCountMap);

  /**
   *  Create a list of message streams for topics matching a wildcard.
   *
   *  @param topicFilter a TopicFilter that specifies which topics to
   *                    subscribe to (encapsulates a whitelist or a blacklist).
   *  @param numStreams the number of message streams to return.
   *  @param keyDecoder a decoder that decodes the message key
   *  @param valueDecoder a decoder that decodes the message itself
   *  @return a list of KafkaStream. Each stream supports an
   *          iterator over its MessageAndMetadata elements.
   */
  public &lt;K,V&gt; List&lt;KafkaStream&lt;K,V&gt;&gt;
    createMessageStreamsByFilter(TopicFilter topicFilter, int numStreams, Decoder&lt;K&gt; keyDecoder, Decoder&lt;V&gt; valueDecoder);

  /**
   *  Create a list of message streams for topics matching a wildcard, using the default decoder.
   */
  public List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt; createMessageStreamsByFilter(TopicFilter topicFilter, int numStreams);

  /**
   *  Create a list of message streams for topics matching a wildcard, using the default decoder, with one stream.
   */
  public List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt; createMessageStreamsByFilter(TopicFilter topicFilter);

  /**
   *  Commit the offsets of all topic/partitions connected by this connector.
   */
  public void commitOffsets();

  /**
   *  Shut down the connector
   */
  public void shutdown();
}

</code></pre>

<p>다음 링크에서 이 consumer API를 사용하는 방법을 확인 할 수 있습니다. <a href="https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example">관련 링크</a></p>

<h3 id="2-2-2-old-simple-consumer-api:02db276f177c9ea394e0f74e7b2c213a">2.2.2 Old Simple Consumer API</h3>

<pre><code class="language-java">class kafka.javaapi.consumer.SimpleConsumer {
  /**
   *  Fetch a set of messages from a topic.
   *
   *  @param request specifies the topic name, topic partition, starting byte offset, maximum bytes to be fetched.
   *  @return a set of fetched messages
   */
  public FetchResponse fetch(kafka.javaapi.FetchRequest request);

  /**
   *  Fetch metadata for a sequence of topics.
   *
   *  @param request specifies the versionId, clientId, sequence of topics.
   *  @return metadata for each topic in the request.
   */
  public kafka.javaapi.TopicMetadataResponse send(kafka.javaapi.TopicMetadataRequest request);

  /**
   *  Get a list of valid offsets (up to maxSize) before the given time.
   *
   *  @param request a [[kafka.javaapi.OffsetRequest]] object.
   *  @return a [[kafka.javaapi.OffsetResponse]] object.
   */
  public kafka.javaapi.OffsetResponse getOffsetsBefore(OffsetRequest request);

  /**
   * Close the SimpleConsumer.
   */
  public void close();
}
</code></pre>

<p>대부분의 애플리케이션에서 고수준 Consumer API이면 충분합니다. 몇몇 애플리케이션은 고수준 Consumer API에서 지원하지 않는 기능을 요구하기도 합니다(예: consumer를 재시작할 때 초기 offset을 설정하고자 하는 기능). 이러한 애플리케이션에서는 저수준 SimpleConsumer API로 대체하면 됩니다. 로직이 조금더 복잡해 질 것입니다. 예제 코드는 다음 링크에서 확인 할 수 있습니다. <a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example">(예제 코드 링크)</a></p>

<h3 id="2-2-3-새버전의-consumer-api:02db276f177c9ea394e0f74e7b2c213a">2.2.3 새버전의 Consumer API</h3>

<p>새로 통합된 consumer API는 0.8 버전의 고수준 API와 저수준 API의 차이를 제거하고 있습니다.  사용자는 다음과 같은 메이븐 관리 기능을 사용하여 클라이언트 jar의 의존성을 추가하여 클라이언트를 사용할 수 있습니다. (새로운 버전이 릴리즈 되면 버전 넘버를 변경해야 합니다.)</p>

<p>Consumer를 사용하는 방법에 대산 예제는 다음 JavaDoc 링크에서 확인 할 수 있습니다:<a href="http://kafka.apache.org/090/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html">Javadoc 링크</a></p>

<h1 id="설정:02db276f177c9ea394e0f74e7b2c213a">설정</h1>

<p>Kafka는 설정을 위해서 프로퍼티 파일 포멧에 키-값 형식을 사용합니다. 이러한 설정 값은 파일 포멧이나 프로그램적인 설정으로 제공될 수 있습니다.</p>

<h2 id="3-1-브로커-설정:02db276f177c9ea394e0f74e7b2c213a">3.1 브로커 설정</h2>

<p>주요 설정 항목은 다음과 같습니다.</p>

<ul>
<li>broker.id</li>
<li>log.dirs</li>
<li>zookeeper.connect</li>
</ul>

<h2 id="3-1-broker-config:02db276f177c9ea394e0f74e7b2c213a">3.1 Broker Config</h2>

<p>토픽 레벨 설정과 기본값은 아래에서 다루겠습니다.</p>

<table>
<thead>
<tr>
<th align="left">이름</th>
<th align="left">설명</th>
<th align="left">타입</th>
<th align="left">기본값</th>
<th align="left">유효값</th>
<th align="left">중요도</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">zookeeper.connect</td>
<td align="left">Zookeeper 호스팅 문자열</td>
<td align="left">String</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">advertised.host.name</td>
<td align="left">Clinet가 사용할 수 있도록 ZooKeeper가 공개하는 호스트 명, IaaS 환경에서, broker가 바인드 된 인터페이스와 달라야 하는 경우도 존재합니다. 설정되어 있는 host.name의 값을 사용할 것입니다. host.name조차도 설정이 되어 있지 않다면 java.net.InetAddress().getCanonicalHostName()의 반환 값을 사용할 것입니다.</td>
<td align="left">String</td>
<td align="left">null</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">advertised.listeners</td>
<td align="left">설정된 리스너와 다른 경우에 클라이언트가 사용할 수 있도록 Zookeeper에 공개된 리스너 정보, IaaS 환경에서 브로커가 바인드 되는 인터페이스와 달라지는 경우가 발생합니다. 이 속성이 설정되지 않는다면 listeners 속성값을 사용합니다.</td>
<td align="left">String</td>
<td align="left">null</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">advertised.port</td>
<td align="left">클라이언트가 사용할 Zookeeper에 공개된 포트입니다. IaaS 환경에서 브로커가 바인드된 포트와 다른 경우가 발생할 수 있습니다. 이 값이 설정되어 있지 않는다면 브러커가 바인드 되는 포트값을 사용합니다.</td>
<td align="left">int</td>
<td align="left">null</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">auto.create.topics.enable</td>
<td align="left">서버에 토픽 자동 생성을 활성화 함</td>
<td align="left">boolean</td>
<td align="left">true</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">auto.leader.rebalance.enable</td>
<td align="left">지동 리더 밸런스 활성화. 백그라운드 쓰레드는 리터 밸런스를 체크하고 정해전 인터벌이 필요하다면 리더 밸런스를 트리거 함</td>
<td align="left">boolean</td>
<td align="left">true</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">background.threads</td>
<td align="left">다양한 백그라운드 프로세스 작업을 수행하는 쓰레드의 갯수 지정</td>
<td align="left">int</td>
<td align="left">10</td>
<td align="left">[1,&hellip;]</td>
<td align="left">high</td>
</tr>

<tr>
<td align="left">broker.id</td>
<td align="left">서버를 위한 브로커 아이디. Zookeeperrk 생성한 브러커 ID와 사용자가 설정한 브러커 아이디가 충돌하는 것을 방지하기 위해서 MaxReservedBrokerId 속성을 추가함. Zookeeper가 생성하는 순차 번호는 MaxReservedBrokerId+1로 부터 시작함.</td>
<td align="left">int</td>
<td align="left">-1</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">compression.type</td>
<td align="left">지정한 토픽의 압축 타입을 지정함. 이 속성은 표준 압축 코텍을 수용(&lsquo;gzip&rsquo;, &lsquo;snappy&rsquo;, lz4). 추가적으로 &lsquo;uncompressed&rsquo;와 &lsquo;producer&rsquo; 를 수용함.&lsquo;uncompressed&rsquo;는 압축을 적용하지 않는 옵션임. &lsquo;producer&rsquo;는 프로듀서에 설정된 압축 코텍을 유지하겠다는 의미임</td>
<td align="left">Strng</td>
<td align="left">producer</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">delete.topic.enable</td>
<td align="left">토픽 삭제를 활성화. 이 설정이 비활성화 되어 있다면 관리 툴을 잉요한 토픽 삭제는 실제 영향을 미치지 않음&rdquo;</td>
<td align="left">boolean</td>
<td align="left">false</td>
<td align="left"></td>
<td align="left">false</td>
</tr>

<tr>
<td align="left">host.name</td>
<td align="left">브로커의 호스트 명. 설정이 되어 있다면 이 주소에 바인드 됨. 설정이 되어있지 않는다면. 모든 인터페이스에 바인드 됨</td>
<td align="left">String</td>
<td align="left">&rdquo;&rdquo;</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">leader.imbalance.check.interval.seconds</td>
<td align="left">컨트롤러가 트리거하는 파티션 리벨런스 체크의 주기</td>
<td align="left">long</td>
<td align="left">300</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">leader.imbalance.per.broker.percentage</td>
<td align="left">브로커 별로 허용된 리더 불균형의 비율. 브러커에 설정된 이 속성은 백분률 단위임</td>
<td align="left">int</td>
<td align="left">10</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">listeners</td>
<td align="left">리스너 목록으로 URI의 컴마 분리, hostname을 0.0.0.0으로 지정하는 것은 모든 인터페이스에 바인딩하는 것임. hostname을 공백으로 남기는 것은 기본 인터페이스에 바인딩하는 설정. 예제: PLAINTEXT://myhost:9092,TRACE://:9091<br/> PLAINTEXT://0.0.0.0:9092, TRACE://localhost:9093</td>
<td align="left">String</td>
<td align="left">null</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">log.dir</td>
<td align="left">로그 데이터가 유지되는 디렉터리, log.dirs이 보조 속성</td>
<td align="left">String</td>
<td align="left">/tmp/kafka-logs</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">log.dirs</td>
<td align="left">로그 데이터를 저장하는 디렉토리 목록, 이 파라미터를 설정하지 않을 경우, log.dir 파라미터를 사용.</td>
<td align="left">String</td>
<td align="left">null</td>
<td align="left"></td>
<td align="left">High</td>
</tr>

<tr>
<td align="left">log.flush.interval.messages</td>
<td align="left">메세지가 디스크에</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>

<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>

<hr />

<p>주요 설정 속성은 다음과 같습니다.</p>

<ul>
<li>broker.id</li>
<li>log.dirs</li>
<li>zookeeper.connect</li>
</ul>

<p>Topic 관련 설정과 기본값은 이래에서 자세히 설명하겠스빈다.</p>

<p>Broker 설정에 대한 더욱 자세한 정보는 kafka.server.KafkaConfig 스칼라 클래스에서 찾을 수 있습니다.</p>

<p>Topic-Level Configuration: Topic 관련 설정은 글로벌 디폴트 뿐만와 선택적이며 Topic 별로 재정의되는 것 모두를 지원합니다. Topic 별 설정이 값이 제시되지 않는다면 글로벌 기본 값을 사용합니다. Topic을 생성할 때에 Topic 설정 값을 재정의를 할 수 있습니다. 이때 &ndash;config 옵션을 사용하여 하나 이상의 값을 재정의 합니다. 다음 예제는 이름이 my-topic인 Topic을 생성하는 예입니다. 이 예제에서는 최대 메세지 사이즈와 플러쉬 율을 재정의 합니다.</p>

<pre><code>bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic my-topic --partitions 1
 --replication-factor 1 --config max.message.bytes=64000 --config flush.messages=1
</code></pre>

<p>이렇게 재정의된 값은 나중에 topic 명령어인 alter를 사용하여 변경될 수 있습니다. 다음 명령은 my-topic의 max message size를 수정하는 예입니다.</p>

<pre><code class="language-bash">bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic my-topic
 --config max.message.bytes=128000
</code></pre>

<p>이렇게 재정의된 설정 값을 제거할 수도 있습니다.</p>

<pre><code> &gt; bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic my-topic
    --deleteConfig max.message.bytes
</code></pre>

<p>다음은 topic-level configuration입니다. 각 프로퍼티에 대한 서버의 기본 설정은 &ldquo;server default property&rdquo;컬럼에서 확인 할 수 있습니다. 서버 설정으로 적용된 기본값은 변경이 가능합니다.</p>

<table>
<thead>
<tr>
<th align="left">프로퍼티</th>
<th align="left">디폴트</th>
<th align="left">Server Default Property</th>
<th align="left">설명</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">cleanup.policy</td>
<td align="left">delete</td>
<td align="left">log.cleanup.policy</td>
<td align="left">&ldquo;delete&rdquo;와 &ldquo;compact&rdquo; 중 하나의 문자열. 이 문자열은 오래된 로그 세그먼트에 적용할 보관 정책을 결정하는 문자열임. 기본 정책은 &ldquo;delete&rdquo;로 보관 시간 혹은 사이즈 제한을 초과 할 때 오래된 세그먼트를 폐기합니다. &ldquo;compact&rdquo;로 설정하면 토픽에 로그를 압축합니다.</td>
</tr>

<tr>
<td align="left">delete.retention.ms</td>
<td align="left">86400000,<br/>24 시간</td>
<td align="left">log.cleaner.delete.retention.ms</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">flush.messages</td>
<td align="left">None</td>
<td align="left">log.flush.interval.messages</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">flush.ms</td>
<td align="left">None</td>
<td align="left">log.flush.interval.ms</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">index.interval.bytes</td>
<td align="left">4096</td>
<td align="left">log.index.interval.bytes</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">max.message.bytes</td>
<td align="left">1,000,000</td>
<td align="left">message.max.bytes</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">min.cleanable.dirty.ratio</td>
<td align="left">0.5</td>
<td align="left">log.cleaner.min.cleanable.ratio</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">min.insync.replicas</td>
<td align="left">1</td>
<td align="left">min.insync.replicas</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">retention.bytes</td>
<td align="left">None</td>
<td align="left">log.retention.bytes</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">retention.ms</td>
<td align="left">7 days</td>
<td align="left">log.retention.minutes</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">segment.bytes</td>
<td align="left">1 GB</td>
<td align="left">log.segment.bytes</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">segment.index.bytes</td>
<td align="left">10 MB</td>
<td align="left">log.index.size.max.bytes</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">segment.ms</td>
<td align="left">7 days</td>
<td align="left">log.roll.hours</td>
<td align="left"></td>
</tr>

<tr>
<td align="left">segment.jitter.ms</td>
<td align="left">0</td>
<td align="left">log.roll.jitter.{ms,hours}</td>
<td align="left"></td>
</tr>
</tbody>
</table>

<h1 id="todo:02db276f177c9ea394e0f74e7b2c213a">todo</h1>
<div class="footnotes">

<hr />

<ol>
<li id="fn:02db276f177c9ea394e0f74e7b2c213a:log-retaintion">설정 명인지 확인하고 번역여부 다시 평가
 <a class="footnote-return" href="#fnref:02db276f177c9ea394e0f74e7b2c213a:log-retaintion"><sup>[return]</sup></a></li>
</ol>
</div>

  </div>
  
  <div>
    <hr/>
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="크리에이티브 커먼즈 라이선스" style="border-width:0" src="/images/creative.png" /></a><a href='https://www.facebook.com/alvinkim082' target='_blank'>taewanme</a>의 저작물인 이 저작물은(는) <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">크리에이티브 커먼즈 저작자표시-비영리-동일조건변경허락 4.0 국제 라이선스</a>에 따라 이용할 수 있습니다.
    <hr/>
  </div>
  <div id="disqus_thread"></div>

  <br/><br/>
    <div>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-8469722754608892"
     data-ad-slot="5594090168"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  </div>
</div>


<script type="text/javascript">
    var disqus_shortname = "taewankim";
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>



<script src="http://taewan.kim/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script>
  var _gaq=[['_setAccount','UA-73312251-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
</script>


</body>
</html>
