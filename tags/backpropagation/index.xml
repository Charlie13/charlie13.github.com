<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Backpropagation on taewan.kim</title>
    <link>/tags/backpropagation/</link>
    <description>Recent content in Backpropagation on taewan.kim</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Nov 2017 21:28:14 +0900</lastBuildDate>
    
	<atom:link href="/tags/backpropagation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>신경망 Weight&amp;Bias Shape의 일반화</title>
      <link>/post/backprop_formula/</link>
      <pubDate>Wed, 29 Nov 2017 21:28:14 +0900</pubDate>
      
      <guid>/post/backprop_formula/</guid>
      <description>Coursera에서 deeplearning.ai가 진행하는 Neural Networks and Deep Learning 강의(4주차: Getting your matrix dimensions)에서 다룬 &amp;ldquo;Neural Network의 Weight와 Bias Shape 계산 일반화&amp;ldquo;를 정리합니다.
Forward Propagation L개의 레이어로 구성된 신경망의 Forward Propagation은 다음과 같이 유도할 수 있습니다.
 $$ \begin{align} Z^{[1]} &amp;amp; = W^{[1]}X + b^{[2]} \\
A^{[^1]} &amp;amp; = g^{[1]}(Z^{[1]}) \\
Z^{[2]} &amp;amp; = W^{[2]}A^{[1]}X + b^{[2]} \\
A^{[^2]} &amp;amp; = g^{[2]}(Z^{[2]}) \\
&amp;amp; &amp;hellip;.. \\
Z^{[l]} &amp;amp; = W^{[l]}A^{[l-1]}X + b^{[2]} \\</description>
    </item>
    
    <item>
      <title>Neural Network의 Backward Propagation의 일반화</title>
      <link>/post/backpropagation/</link>
      <pubDate>Mon, 01 Dec 2014 21:28:14 +0900</pubDate>
      
      <guid>/post/backpropagation/</guid>
      <description>Coursera에서 deeplearning.ai가 진행하는 Neural Networks and Deep Learning 강의(4주차: Forward and Backward Propagation)에서 다룬 &amp;ldquo;Neural Network의 Forward Propagation과 Backward Propagation 일반화&amp;ldquo;를 정리합니다.
Neural Network에서는 Forward Propagation을 이용하여 입력한 데이터의 추정결과를 계산합니다. 지도학습에서는 입력 데이터의 추정결과와 해당 데이터의 실제 정답인 레이블(Label)과의 오차를 계산합니다. 이때 &amp;ldquo;Error Function/Loss Function&amp;ldquo;을 사용하여 추정결과와 레이블의 오차를 계산합니다. &amp;ldquo;Error Function/Loss Function&amp;ldquo;을 각 레이어의 출력값과 Weight, Bias로 미분하여 각 레이어의 Weight 와 Bias가 오차에 미치는 영향도를 계산합니다. 이 결과를 각 레이어의 Weight와 Bias에 반영(업데이트) 합니다.</description>
    </item>
    
  </channel>
</rss>