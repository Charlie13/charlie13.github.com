<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>딥러닝 on taewan.kim</title>
    <link>/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/</link>
    <description>Recent content in 딥러닝 on taewan.kim</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jan 2018 21:28:14 +0900</lastBuildDate>
    
	<atom:link href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>CNN, Convolution Neural Network 요약</title>
      <link>/post/cnn/</link>
      <pubDate>Thu, 04 Jan 2018 21:28:14 +0900</pubDate>
      
      <guid>/post/cnn/</guid>
      <description>Fully Connected Layer1 만으로 구성된 인공 신경망의 입력 데이터는 1차원(배열) 형태여야 합니다. 한 장의 컬러 사진은 3차원 데이터입니다. 배치 모드에 사용되는 여러장의 사진은 4차원 데이터입니다. 사진 데이터로 전연결(FC, Fully Connected) 신경망을 학습시켜야 할 경우에, 3차원 혹은 4차원 사진 데이터를 1차원으로 평면화시켜야 합니다. 사진 데이터를 평면화 시키는 과정에서 공간 정보가 손실될 수밖에 없습니다. 결과적으로 사진 인식의 중요한 정보 부족으로 인공 신경망의 인식률을 높이는 데 한계가 있습니다. 이미지의 공간 정보를 유지한 상태로 학습 가능한 모델이 바로 CNN(Convolutional Neural Network)입니다.</description>
    </item>
    
    <item>
      <title>신경망 W 행렬 표기법: &#39;ij&#39;/&#39;ji&#39; 의 차이점?</title>
      <link>/post/wij_and_wji/</link>
      <pubDate>Sat, 23 Dec 2017 21:28:14 +0900</pubDate>
      
      <guid>/post/wij_and_wji/</guid>
      <description>제가 처음에 딥러닝을 학습할 때 가장 혼란스러웠던 것은 입력 레이어의 데이터와 가중치 W의 합 표현하는 &amp;ldquo;Z(Weighted Sum)&amp;rdquo; 수식이 문서마다 다른 것이었습니다.
  &amp;lt;식 1&amp;gt;. Z(Weighted Sum)을 표현하는 수식 $$ \begin{align} Z^{[l]} &amp;amp; = W^{[l]T}A^{[l-1]} &amp;amp; (1) \\
Z^{[l]} &amp;amp; = W^{[l]}A^{[l-1]} &amp;amp; (2) \end{align} $$   &amp;lt;식 1&amp;gt;의 (1)과 (2)는 다른 수식임에도 어떤 자료는 (1)과 같이 표현하고 어떤 자료는 (2)와 같이 표현합니다. &amp;lt;식 1&amp;gt; 표기법의 각 요소는 다음과 정리할 수 있습니다.</description>
    </item>
    
  </channel>
</rss>