+++
date = "2017-12-11T21:28:14+09:00"
description = "Coursera에서 deeplearning.ai가 운영하는 강좌 Course 2의 1주차 강의를 정리합니다 . ."
title = "Coursera의 deeplearning.ai Course2 강좌 1주차 정리"
thumbnailInList = "https://taewanmerepo.github.io/2017/12/DLcourse2week1/list.jpg"
thumbnailInPost = ""
tags = ["deep learning", "Neural Network", "Coursera", "Andrew NG", "deeplearning.ai", "Course 2", "Week 1", "5-Course Specialization"]
categories = ["Machine Learning"]
author = "taewan.kim"
language = ""  
jupyter = "false"
+++

 Coursera에서 deeplearning.ai가 진행하고 있는 Deep Learning 강좌 "__5-course Specialization__"의 두 번째 과정인 "__Improving Deep Neural Network__"의 1주차 강의를 정리합니다. 강좌의 세부 정보는 다음과 같습니다.

## 0. 강의 소개

본 문서에서 정리하는 강의 정보는 다음과 같습니다.

### 0.1 강좌 세부 정보
 - Mock: Coursera
 - 운영: deeplearning.ai
 - 과정명: 5-course Specialization
 - 코스명: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizatio
 - 주차: Week 1
 - 주제: Practical aspect of Deep Learning

### 0.2 1주차 강의 학습 목표

1주차 강의 학습 목표는 다음과 같습니다.

1. 초기화 유형 변경은 다른 결과를 유도함을 이해
1. 복잡한 신경망에서 초기화의 중요성 파악
1. Train/Dev/Test set의 차이점 파악
1. 모델에서 bias와 variance 이슈 진단
1. Dropout과 L2 정규화 같은 정규화 기법 사용 시기와 방법 파악
1. Vanish gradient와 Exploding gradient와 같은 딥러닝 이슈를 이해하고 해결 방법 이해
1. 기울기 검사를 사용하여 역전파 구현 정확성 파악

1주차 강의는 머신러닝 애플리케이션 구성, 신경망 정규화, 최적화 3가지로 구성됩니다. 마지막으로 퀴즈 1개과 과제가 3개가 있습니다.

----

## 1. Setting up your Machine Learning Application

### 1.1 Train/ Dev /Test sets

머신러닝에서 하이퍼파라미터(Hyperparameter)란 학습 프로세스가 시작하기 전에 사전에 결정되어야 하는 파라미터입니다.

#### 1.1.1 Train/ Dev /Test sets
- 신경망 학습시 초기 결정해야 할 하이퍼파라미터 유형
  - Layer 수 (#layer)
  - 은닉층의 노드 수 (unit 수) [^1]
  - Learning rate
  - 레이어별 활성화 함수


[^1]: Input layer와 Output layer의 노드 수는 Hyperparameter로 분류되지 않습니다. 입력층과 출력층의 노드 수는 데이터의 유형과 목적에 따라서 결정됩니다. 입력 데이터의 Input Feature 수로 입력층의 노드 수는 결정되고, Classifction의 경우 분류 클래스의 수로 출력층의 노드 수가 결정됩니다. 따라서

한번에 최적의 하이퍼파라미터를 결정할 수 없으며, 반복적인 프로세스로 최적화 하이퍼파라미터 결정

- 인공신경망 반복적 프로세스
  1. 인공 신경망 디자인
  1. 인공 신경망 구현
  1. 실험
  1. 인공 신경망 성층 평가
  1. 인공 신경망 재구성 (Hyperparameter 변경)
  1. 코드 수정
  1. 실험
  1. 인공 신경망 성층 평가
  1. 5~9번 반복  

----

최근 Deep Learning 적용 분야
- 자연어 처리(NLP)
- Computer Vision
- 음성인식 (Speech Recognition)
- Structured Data
  - 광고
  - 웹 검색
  - 컴퓨터 보안
  - 물류
  - 등등등...

----

학습, 개발, 테스트 셋으로 데이터를 잘 만들어 놓으면 작업 효율성이 증가됩니다.

- 전통적인 데이터 구성
  - 데이터를 Train set, Cross Validation Set, Test Set으루 구분
  - Cross Validation Set은 Development Set 혹은 Dev Set이라고 함
  - Cross Validation Set은 개발 과정에서 최적의 Hyperparameter 및 알고리즘, 모델 테스트 용도로 사용
  - Test set은 학습 종료 후 알고리즘 평가에 사용됨
  - 데이터 구성 비율
    - 2개 유형으로 구분=> Train Set:Test Set = 7:3
    - 3개 유형으로 구분=> Train Set:Dev Set:Test Set = 6:2:2
  - 10,000 건의 데이터 수준에서 적합한 비율

빅데이터 시대에 데이터가 급격하게 증가한 현재, 전통적인 방식으로 데이터를 비율로 구분하는 방식을 사용하지는 않음

- 데이터가 클 경우 Test Set와 Dev Set의 비율을 줄임
- Dev Set의 목적은 신경망에 더 적합한 알고리즘를 찾는 것에 있음[^2]
- Dev Set의 데이터 규모: 하이퍼파라미터 변경에 대한 평가와 변경 결정이 가능한 규모면 충분, Dev Set 용도로 전체 데이터의 20%를 확보할 필요 없음
- Test Set의 목적: 인공 신경망 학습에 대한 신뢰도 측정
- 데이터 분류 예제(전체 데이터: 100,000건)
  - Train set: 98,000건
  - Dev Set: 10,000건
  - Test Set: 10,000
  - 비율=> Train Set:Dev Set:Test Set = 98%:1%:1%

[^2]: Dev Set(Validation Set)은 학습 과정에서 학습의 overfitting 여부를 체크하는 용도로 사용됩니다. Training error는 줄고 있지만 Validation Set의 error는 줄어들다가 증가한다면 그 Epoch을 기준으로 과적합이 발생한 시점을 볼 수 있습니다. Test Set은 학습이 끝난 후 신경망의 error를 체크하는 용도로 사용됩니다. Validation Set과 Test Set은 인공 신경망의 학습에 노출되면 안됩니다.

학습 데이터를 백만건 이상 확보한 상태라면 Dev Set과 Test Set의 비율을 더 줄일 수 있습니다.

- Train_Set:Dev_Set:Test_Set = 99.5%:0.4%:0.1%
- 학습 데이터가 작을 경우 전통적인 데이터 분류 비율을 사용할 수도 있음
- Dev Set과 Test Set에 대한 더 명확한 규모는 다음 강좌에서 다룰 예정

#### 1.1.2 Mismatched train/test distribution

데이터 분포가 다른 Train Set과 Test Set으로 학습하는 경우가 많아지고 있다.
다음은 다은 소스로 부터 확보한 데이터로 인공 신경망을 학습시키는 예입니다.

- 사진을 업로드하는 앱에서 고양이 사진을 찾아 사용자에게 제시하는 기능 개발(고양이 애호가 앱)
- 학습 데이터는 인터넷에서 크롤링한 고양이 사진을 이용
- dev set과 test set은 앱에서 사용자가 업로드한 사진을 사용
- 학습 데이터는 높은 해상도와 전문적이고 매우 좋은 사진
- dev set와 test set은 핸드폰으로 찍은 저해상도 사진
- 학습 데이터와 dev/test set은 데이터 분포가 완전히 다를 수 있음
- 이 경우 dev set과 test set은 동일한 데이터 분포를 갖어야 함
- 딥러닝 알고리즘은 학습 데이터를 더 많이 필요로 함, 최대한 학습 데이터 확보를 위해 다양한 전략을 사용

이와 같이 데이터 출처와 분포가 다른 train/test set 학습시키는 것을 "Rule of Thumb"[^3]이라고 합니다.

[^3]: "__Rule of Thumb__"는 주목 구구식 접근법으로 번역 가능합니다. 엄지 손가락 한마디로 1인치를 계산하는 모습에서 유례된 표현입니다. 일관성이 떨어지더라도 학습 데이터를 최대한 확보하는 방식을 의미합니다.

test set이 없을 수도 있습니다.

- test set의 목적은 인공 신경망의 성능에 대한 편견없는 평가 수행에 있음
- dev set만 있고 test set이 없다면, 학습 데이터로 인공 신경망을 학습시킨 후, dev set으로 다른 모델을 평가합니다.
- 이 절차를 좋은 모델을 확보할 때 까지 반복합니다.
- dev set과 test set을 반드시 구분할 필요는 없음

#### 1.1.3 요약

- 학습/개발/테스트 데이터를 고전적 방식으로 6:2:2 비율로 관리할 필요는 없음
- 데이터가 많다면 학습 데이터를 가장 크게 만들고 개발/테스트 데이터의 비중을 낮춤
- 학습 데이터와 개발/테스트 데이터는 데이터 분포가 다를 수 있음
- 이때 개발/테스트 데이터 분포는 맞춰야 함
- 개발/테스트 데이터 분류가 반드시 필요한 상황이 아님

----

### 1.2 Bias / Variance


{{< img src="https://taewanmerepo.github.io/2017/12/DLcourse2week1/010.jpg"
title="그림 1"
caption="Bias와 Variance" >}}

그림 1은 Bias와 Variance를 설명합니다. Bias는 중앙으로 부터 떨어진 정도입니다. 샘플링을 할 때 값이 달라지는 정도를 Variance라도 합니다.
Bias가 작고 Variance가 낮은 첫 번째 이미지가 이상적인 모습입니다.

{{< img src="https://taewanmerepo.github.io/2017/12/DLcourse2week1/020.jpg"
title="그림 2"
caption="Bias-Variance off" >}}

<그림 2>에서 구분 선에 따라서 Bias와 Variance는 다음과 같습니다.

||bias|variance|설명|
|---|---|---|---|
|라인 1|높음|낮음|- sample에 따라서 라인의 변화 정도가 작으면 variance가 낮음</br>- under-fitting에서는 bias가 큼|
|라인 2|낮음|높음|- sample에 따라서 라인의 변화 정도가 심하면 variance가 큼</br>- over-fitting에서는 bias가 작아짐|

{{< img src="https://taewanmerepo.github.io/2017/12/DLcourse2week1/030.jpg"
title="그림 2"
caption="Bias-Variance vs over/underfitting" >}}

2 차원의 데이터는 시각화를 통해서 Bias와 Variance를 쉽게 파악할 수 있지만,
고 차원으로 올라가면 시각화로 구분하기는 어렵습니다. Bias와 Variance를 다음과 같이 구분할 수 있습니다.

||case 1|case 2|case 3|case 4|case 5|
|---|---|---|---|---|---|
|human error<br/>(optimal error, base error)|0%|0%|0%|0%|15%|
|train set error|1%|15%|15%|0.5%|15%|
|dev set error|11%|16%|30%|1%|16%|
|설명|High Variable<br/>Overfitting|High bias|high variable<br/>high bias|low variable<br/>low bias|low variable<br/>low bias|

Case 5의 경우 Human 에러가 15%이며 human error를 기준으로 볼 때, training set error는 낮은 수준의 에러로 분류합니다.
이 경우는 아마도 흐릿한 사진을 입력데이터로 사용하는 등 노이즈가 많은 데이터를 사용하는 예입니다.

#### 1.2.1 요약
- Train error와 dev error로 부터 High bias와 High Variable을 분석할 수 있음
- High bias
  - train error가 큼
  - Under-fitting일 가능성이 큼
- High variance
  - train error << dev error
  - Overfitting일 가능성이 큼

### 1.3 Basic Recipe for Machine Learning

- 신경망을 개발함에 있어서 적용 가능한 기본적인 리스피를 소개 <그림 3 참조>

{{< img src="https://taewanmerepo.github.io/2017/12/course2week1/010.jpg"
title="그림 3"
caption="Machine Learning 기본 레시피" >}}

<그림 3>은 다음과 같은 순서로 동작합니다.

1. 초기 신경망 모델 구현
1. 준비한 데이터로 학습
1. 학습 완료 후 High Bias 여부 확인
  - 학습 데이터의 정확도 체크
  - High Bias가 발생했다면 다음 항목 초지 후 2번으로 이동
    - 은닉 레이어 추가
    - 은닉 레이어에 노드 추가
    - 학습 시간 연장 (epoch 증가)
    - 전문 최적화 기법법 적용
  - High Bias가 발생하면 않으면 다음으로 넘어감
1. 학습 완료 후 High Variance 발생 여부 확인
  - High Variance가 발생했다면 다음 조치 후 2번으로 이동
    - 학습 데이터 추가 (추가 학습 데이터 확보가 가능하다면)
    - Regularization (추가 학습 데이터 확보가 불가능 하다면)
  - High Variance가 발생하지 않는다면 다음으로 넘어감
1. low Bias/Variance 여부 확인
  - 만족하지 못할 경우 2번으로 이동
1. Low Bias/Variance 만족시 종료


## Regularizing your neural network
## Setting up your optimization problem
### Regularization
### Why regularization reduces overfitting?
### Dropout regularization
### Understanding Dropout
### Other regularization methods
## Setting up your optimization problem
### Nomalizaing inputs
### Vanishing/Exploding gradients
### Weight Initialization for Deep Networks
